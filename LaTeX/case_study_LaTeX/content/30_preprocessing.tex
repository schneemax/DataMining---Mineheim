\section{Preprocessing}\label{chap:preprocessing}
Before the models for predicting the quality of a wine were created, the data had to be preprocessed accordingly. Preprocessing is important in order to \enquote{resolve several types of problems include noisy data, redundancy data, missing data values, etc.} \citep[p. 116]{Kotsiantis2006}. The preprocessing of the utilized dataset for the characteristics as well as the quality of wine can be divided into three parts.

First of all, duplicates needed to be deleted and missing values must be handled in an appropriate way. The data set of 6,497 entries did not include any duplicates. Consequently, no rows were deleted. As analyzed in section \ref{sec:data_structure}, the data set had 34 missing values or so-called null values in seven different columns, which were imputed with the mean value.

In the second step the columns were preprocessed. Numerical values were normalized, and categorical values were converted into numerical values. According to Kotsiantis et al. normalization is a \enquote{\enquote{scaling down} transformation of the features.} \citep[p. 113]{Kotsiantis2006} Therefore, all numerical features as for instance pH-values, and alcohol were normalized. The categorical value type, which determines whether the wine is red or white, was encoded to numerical values with the help of the \textit{Ordinal Encoder}. \citep{OrdinalEncoder2021} As the target variable quality was imbalanced, a binning of three classes, low, medium and high quality, was applied. No additional features were generated, as the dataset mainly contains chemical parameters as e.g., pH-value or sulphates, which cannot be combined to build new features. The feature selection and correlation are part of the adaption phase of the models as the feature selection differs between the applied algorithms.

In the last step, the feature and target variable were separated and stored in two different dataframes. Afterwards, the test and train split was applied with a test size of 20 \% of the available data and a stratification of the target variable. The in section \ref{sec:data_structure} detected outliers were removed from the train set on the basis of a 90 \% confidence interval (CI). \citep{AskPython2021} Therefore, every value that was not included in the 90 \% CI was deleted.

% Preprocessing
% – Are missing values replaced (in case needed)?
% – Checked for outliers (and handled them)?
% – Validity tests of attributes (Height above sea level < 9000)?
% – Check for inconsistencies (age=42, birthday=03/07/1997)

% Check for duplicates
% – Data normalization
% – Additional features generated?
% – Has binning been tried out?
% – Correlation analysis implemented?
% – Feature subset selection implemented?
% • External Knowledge:
% – Are additional datasets used?

%// Single Source of truth preprocessing: /DataMining---Mineheim/Code/Random%20Forest/Wine_Quality_Prediction_rf_preventing_overfitting.ipynb